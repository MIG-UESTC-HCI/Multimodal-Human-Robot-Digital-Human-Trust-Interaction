# Review-and-Outlook-of-Shared-Multi-Modal-Trustworthy-Human-Machine-Interaction-Research[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/XingfuCao/Review-and-Outlook-of-Shared-Multi-Modal-Trustworthy-Human-Machine-Interaction-Research)

A curated list of research papers in human-machine interaction.

## ðŸ’¬ News
**[2023/04/2]**: Create this repository.

<!-- 1. First Author. **Paper Name**. Conf. [[Paper]]() [[Code]]() [[Website]]() -->

## multimodal human-robot interaction / multimodal fusion<br>
#### 2020
1. Jie Lei, Licheng Yu, et al. **TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval**. 	ECCV 2020. [[Paper]](https://arxiv.org/abs/2001.09099) [[Code1]](https://github.com/jayleicn/TVRetrieval) [[code2]](https://github.com/jayleicn/TVCaption)
2. Ronghang Hu, Amanpreet Singh, et al. **Iterative Answer Prediction with Pointer-Augmented Multimodal Transformers for TextVQA**. 	CVPR 2020. [[Paper]](https://arxiv.org/abs/1911.06258) [[Code]](https://github.com/adlnlp/attention_vl)
3. Mahdi Abavisani, Liwei Wu, et al. **Multimodal Categorization of Crisis Events in Social Media**. CVPR 2020.[[Paper]](https://arxiv.org/abs/2004.04917) [[Code]](https://github.com/PaulCCCCCCH/Multimodal-Categorization-of-Crisis-Events-in-Social-Media)
4. Shaofei Huang, Tianrui Hui, et al.**Referring Image Segmentation via Cross-Modal Progressive Comprehension**. CVPR 2020. [[Paper]](https://arxiv.org/abs/2010.00514) [[Code]](https://github.com/spyflying/CMPC-Refseg)

#### 2021
1. Kranti Kumar Parida, Siddharth Srivastava, et al. **Beyond Image to Depth: Improving Depth Prediction using Echoes**. CVPR 2021. [[Paper]](https://arxiv.org/abs/2103.08468) [[Code]](https://github.com/krantiparida/beyond-image-to-depth)
2. Yapeng Tian, Chenliang Xu.**Can audio-visual integration strengthen robustness under multimodal attacks?**. 	CVPR 2021. [[Paper]](https://arxiv.org/abs/2104.02000) [[Code]](https://github.com/YapengTian/AV-Robustness-CVPR21)

#### 2022
1. Dewang Hou, Yuanyuan Du,et al. **Learning an Efficient Multimodal Depth Completion Model**. ECCV 2022. [[Paper]](https://arxiv.org/abs/2208.10771) [[Code]](https://github.com/dwhou/emdc-pytorch) 
2. Tim Salzmann, Marco Pavone, . **Motron: Multimodal Probabilistic Human Motion Forecasting**. CVPR 2022. [[Paper]](https://arxiv.org/abs/2203.04132) [[Code]](https://github.com/TUM-AAS/motron-cvpr22) 
3. Zi-Yi Dou, Yichong Xu, et al. **An Empirical Study of Training End-to-End Vision-and-Language Transformers**. CVPR 2022. [[Paper]](https://arxiv.org/abs/2111.02387) [[Code]](https://github.com/zdou0830/meter)
4. Matthew Walmer, Karan Sikka, et al. **Dual-Key Multimodal Backdoors for Visual Question Answering**. CVPR 2022. [[Paper]](https://arxiv.org/abs/2112.07668) [[Code]](https://github.com/SRI-CSL/TrinityMultimodalTrojAI)
5. Xiaokang Peng, Yake Wei, et al. **Balanced Multimodal Learning via On-the-fly Gradient Modulation**. CVPR 2022. [[Paper]](https://arxiv.org/abs/2203.15332) [[Code]](https://github.com/gewu-lab/ogm-ge_cvpr2022)
6. Momal Ijaz, Renato Diaz, et al. **Multimodal Transformer for Nursing Activity Recognition**. CVPR 2022. [[Paper]](https://arxiv.org/abs/2204.04564) [[Code]](https://github.com/momilijaz96/mmt_for_ncrc)
7. Yikai Wang, Xinghao Chen, et al. **Multimodal Token Fusion for Vision Transformers**. 	CVPR 2022. [[Paper]](https://arxiv.org/abs/2204.08721) [[Code1]](https://github.com/yikaiw/TokenFusion)[[Code2]](https://github.com/huawei-noah/noah-research/tree/master/TokenFusion)[[Code3]](https://github.com/mindspore-ai/models/tree/master/research/cv/TokenFusion)


#### 2023
1. Yue Wang, Jinlong Peng, et al. **Multimodal Industrial Anomaly Detection via Hybrid Fusion**. CVPR 2023. [[Paper]](https://arxiv.org/abs/2303.00601) [[Code]](https://github.com/nomewang/m3dm)
2. Jiaming Zhang, Ruiping Liu, et al. **Delivering Arbitrary-Modal Semantic Segmentation**. CVPR 2023. [[Paper]](https://arxiv.org/abs/2303.01480) [[Code]](https://github.com/jamycheung/DELIVER)

## shared awareness cues / shared awareness interaction / AR-based human-robot interaction<br>
#### 2020
